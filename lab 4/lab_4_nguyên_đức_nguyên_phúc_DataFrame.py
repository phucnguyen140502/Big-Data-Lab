# -*- coding: utf-8 -*-
"""Lab 4 Nguyên đức Nguyên Phúc Bigdata.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rKHAODR9oHJyWZ34vnkcw2DIllT5U1fQ
"""

!pip install pyspark
!pip install findspark

import findspark
findspark.init()

from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("PySpark_Exercises").getOrCreate()

print("SparkSession is active and ready to use.")

import pandas as pd

# Đọc dữ liệu từ nguồn trực tuyến
url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/KpHDlIzdtR63BdTofl1mOg/owid-covid-latest.csv'
vaccination_data = pd.read_csv(url)

# Hiển thị 5 dòng đầu tiên
vaccination_data.head()

from pyspark.sql.types import StructType, StructField, StringType, LongType

# Định nghĩa schema
schema = StructType([
    StructField("continent", StringType(), True),
    StructField("total_cases", LongType(), True),
    StructField("total_deaths", LongType(), True),
    StructField("total_vaccinations", LongType(), True),
    StructField("population", LongType(), True)
])

# Xử lý dữ liệu để đảm bảo kiểu dữ liệu phù hợp
vaccination_data['continent'] = vaccination_data['continent'].astype(str)
vaccination_data['total_cases'] = vaccination_data['total_cases'].fillna(0).astype('int64')
vaccination_data['total_deaths'] = vaccination_data['total_deaths'].fillna(0).astype('int64')
vaccination_data['total_vaccinations'] = vaccination_data['total_vaccinations'].fillna(0).astype('int64')
vaccination_data['population'] = vaccination_data['population'].fillna(0).astype('int64')

# Tạo Spark DataFrame
spark_df = spark.createDataFrame(vaccination_data[schema.fieldNames()])
spark_df.show()

spark_df.printSchema()

spark_df.select("continent","total_cases").show()

spark_df.filter(spark_df.total_cases > 1000000).show()

from pyspark.sql.functions import format_number

spark_df_with_percentage = spark_df.withColumn("death_percentage", format_number((spark_df.total_deaths / spark_df.population) * 100, 2))

spark_df_with_percentage.show(5)

spark_df.groupBy("continent").agg({"total_deaths": "sum"}).show()

from pyspark.sql import SparkSession
from pyspark.sql.types import IntegerType

def double_deaths(total_deaths):
    return total_deaths * 2

double_deaths_udf = spark.udf.register("double_deaths", double_deaths, IntegerType())

spark_df = spark_df.withColumn("doubled_total_deaths", double_deaths(spark_df.total_deaths))

spark_df.show(5)

spark_df.createOrReplaceTempView("data_v")

spark.sql("SELECT * FROM data_v").show(5)

spark.sql("SELECT continent, total_vaccinations FROM data_v WHERE total_vaccinations > 1000000").show()